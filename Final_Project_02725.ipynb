{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw8XvOm-K7Ns"
      },
      "outputs": [],
      "source": [
        "# TODO: Use RNN to process each protein and produce a hidden state, maybe use an embedding layer\n",
        "# normalize for sequence length somehow\n",
        "# Maybe use LSTM or Transformer instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jADFOxeoLDKk"
      },
      "outputs": [],
      "source": [
        "# TODO: Output layer should produce potential 3mers\n",
        "# linear layer from hidden vector to output classes\n",
        "# use cross entropy loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPW1riQtOlLa",
        "outputId": "ba0e4da8-c527-4fbc-d4cd-48823841fa37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ2IUCjqj-U0",
        "outputId": "310ecd90-1e2c-4154-df37-81ec82ab6bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/841.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/841.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m788.5/841.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install torchsummaryX -q\n",
        "!pip install torchsummaryx==1.1.0 -q\n",
        "!pip install torchmetrics -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUqzLvlckg_4",
        "outputId": "6505ab90-9e13-449d-c510-28d873966038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchsummaryX import summary\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import numpy as np\n",
        "import gc\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torchmetrics.classification import MultilabelF1Score, MultilabelAccuracy, MultilabelSpecificity\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHqnTkrVijHw",
        "outputId": "73774000-a948-4488-ac8d-e83005aa6249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-03 13:02:46--  https://chemdata.nist.gov/download/peptide_library/libraries/human/ION_TRAP/2014_05_29/2014_05_29_human_consensus_final_true_lib.tar.gz\n",
            "Resolving chemdata.nist.gov (chemdata.nist.gov)... 129.6.13.19, 2610:20:6005:13::19\n",
            "Connecting to chemdata.nist.gov (chemdata.nist.gov)|129.6.13.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 573909561 (547M) [application/x-gzip]\n",
            "Saving to: ‘/content/train_data.tar.gz’\n",
            "\n",
            "/content/train_data 100%[===================>] 547.32M  12.8MB/s    in 77s     \n",
            "\n",
            "2024-05-03 13:04:04 (7.09 MB/s) - ‘/content/train_data.tar.gz’ saved [573909561/573909561]\n",
            "\n",
            "--2024-05-03 13:04:04--  https://chemdata.nist.gov/download/peptide_library/libraries/mouse/ION_TRAP/2013_05_20/2013_05_20_mouse_consensus_final_true_lib.tar.gz\n",
            "Resolving chemdata.nist.gov (chemdata.nist.gov)... 129.6.13.19, 2610:20:6005:13::19\n",
            "Connecting to chemdata.nist.gov (chemdata.nist.gov)|129.6.13.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 227578902 (217M) [application/x-gzip]\n",
            "Saving to: ‘/content/valid_data.tar.gz’\n",
            "\n",
            "/content/valid_data 100%[===================>] 217.04M  20.4MB/s    in 21s     \n",
            "\n",
            "2024-05-03 13:04:25 (10.5 MB/s) - ‘/content/valid_data.tar.gz’ saved [227578902/227578902]\n",
            "\n",
            "human_consensus_final_true_lib.msp\n",
            "mouse_consensus_final_true_lib.msp\n"
          ]
        }
      ],
      "source": [
        "!wget -O '/content/train_data.tar.gz' 'https://chemdata.nist.gov/download/peptide_library/libraries/human/ION_TRAP/2014_05_29/2014_05_29_human_consensus_final_true_lib.tar.gz'\n",
        "!wget -O '/content/valid_data.tar.gz' 'https://chemdata.nist.gov/download/peptide_library/libraries/mouse/ION_TRAP/2013_05_20/2013_05_20_mouse_consensus_final_true_lib.tar.gz'\n",
        "# !wget -O '/content/valid_data.tar.gz' 'https://chemdata.nist.gov/download/peptide_library/libraries/proteins/ion_trap/bsa/strict/2011_04_01/2011_04_01_bsa_consensus_final_true_lib.tar.gz'\n",
        "\n",
        "!tar -xvzf '/content/train_data.tar.gz'\n",
        "!tar -xvzf '/content/valid_data.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck5fzd5glF75"
      },
      "outputs": [],
      "source": [
        "AAs = ['A','R','N','D','C','E','Q','G','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
        "THREEMERS = []\n",
        "for i in range(len(AAs)):\n",
        "  for j in range(len(AAs)):\n",
        "    for k in range(len(AAs)):\n",
        "      THREEMERS.append(AAs[i] + AAs[j] + AAs[k])\n",
        "THREEMER_MAP = dict()\n",
        "for i in range(len(THREEMERS)):\n",
        "  THREEMER_MAP[THREEMERS[i]] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI7UAvZhyk2H"
      },
      "outputs": [],
      "source": [
        "# TODO: Dataloader\n",
        "# Process input files into lists of (mass, intensity) pairs for each protein\n",
        "# Convert protein sequence into binary vector of 3-mers\n",
        "class MSDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, file, map=THREEMER_MAP):\n",
        "    with open(file, 'r') as f:\n",
        "      specs = f.read().strip().split('\\n\\n')\n",
        "      self.spectra = []\n",
        "      self.length = len(specs)\n",
        "      output_size = len(THREEMER_MAP)\n",
        "      self.labels = np.zeros((self.length, output_size))\n",
        "      k = 0\n",
        "\n",
        "      for spec in specs:\n",
        "        lines = spec.strip().split('\\n')\n",
        "        seq = lines[0].split('Name: ')[1].split('/')[0]\n",
        "\n",
        "        threemers = set()\n",
        "        for i in range(len(seq) - 2):\n",
        "          threemers.update([seq[i:i+3]])\n",
        "        for t in threemers:\n",
        "          self.labels[k, THREEMER_MAP[t]]= 1\n",
        "\n",
        "        i = 1\n",
        "        while 'Num peaks: ' not in lines[i]:\n",
        "          i += 1\n",
        "        spec_len = int(lines[i].split('Num peaks: ')[1])\n",
        "        spectrum = np.zeros((spec_len, 2))\n",
        "        i += 1\n",
        "        for j in range(i, i + spec_len):\n",
        "          nums = lines[j].split('\\t')\n",
        "          spectrum[j-i,0] = float(nums[0])\n",
        "          spectrum[j-i,1] = float(nums[1])\n",
        "        self.spectra.append(spectrum)\n",
        "        k += 1\n",
        "      self.abundance = np.zeros(output_size)\n",
        "      for i in range(output_size):\n",
        "        self.abundance[i] = self.length / (np.sum(self.labels[:,i]) + 1e-4)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, ind):\n",
        "    spec = torch.FloatTensor(self.spectra[ind])\n",
        "    lbl = torch.tensor(self.labels[ind,:])\n",
        "    return spec, lbl\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    batch_spec, batch_lbl = zip(*batch)\n",
        "\n",
        "    batch_spec_pad = pad_sequence(batch_spec, batch_first=True)\n",
        "    lengths_spec = [len(seq) for seq in batch_spec]\n",
        "\n",
        "\n",
        "    return batch_spec_pad, torch.tensor(lengths_spec), torch.stack(batch_lbl, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ-YWuZqPH3d"
      },
      "outputs": [],
      "source": [
        "# RESNET\n",
        "# Process input files into lists of (mass, intensity) pairs for each protein\n",
        "# Convert protein sequence into binary vector of 3-mers\n",
        "class MSDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, file, map=THREEMER_MAP, bin_size=0.25, max_m_z = 1000):\n",
        "    with open(file, 'r') as f:\n",
        "      specs = f.read().strip().split('\\n\\n')\n",
        "      self.spectra = []\n",
        "      self.length = len(specs)\n",
        "      output_size = len(THREEMER_MAP)\n",
        "      self.labels = np.zeros((self.length, output_size))\n",
        "      k = 0\n",
        "\n",
        "      for spec in specs:\n",
        "        lines = spec.strip().split('\\n')\n",
        "        seq = lines[0].split('Name: ')[1].split('/')[0]\n",
        "\n",
        "        threemers = set()\n",
        "        for i in range(len(seq) - 2):\n",
        "          threemers.update([seq[i:i+3]])\n",
        "        for t in threemers:\n",
        "          self.labels[k, THREEMER_MAP[t]]= 1\n",
        "\n",
        "        i = 1\n",
        "        while 'Num peaks: ' not in lines[i]:\n",
        "          i += 1\n",
        "        spec_len = int(lines[i].split('Num peaks: ')[1])\n",
        "\n",
        "        spectrum = np.zeros((int(max_m_z/bin_size),1))\n",
        "        i += 1\n",
        "        max_peak = 0\n",
        "        min_peak = 100000\n",
        "        for j in range(i, i+spec_len):\n",
        "          nums = lines[j].split('\\t')\n",
        "          peak = float(nums[0])\n",
        "          intensity = float(nums[1])\n",
        "          index = int(peak/bin_size)\n",
        "          if intensity > max_peak:\n",
        "            max_peak = intensity\n",
        "          if intensity < min_peak:\n",
        "            min_peak = intensity\n",
        "          if index < int(max_m_z/bin_size):\n",
        "            spectrum[index][0] = intensity\n",
        "        spectrum = (spectrum - min_peak)/(max_peak - min_peak)\n",
        "        self.spectra.append(spectrum)\n",
        "        k += 1\n",
        "\n",
        "      self.abundance = np.zeros(output_size)\n",
        "      for i in range(output_size):\n",
        "        self.abundance[i] = self.length / (np.sum(self.labels[:,i]) + 1e-4)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, ind):\n",
        "    spec = torch.FloatTensor(self.spectra[ind])\n",
        "    lbl = torch.tensor(self.labels[ind,:])\n",
        "    return spec, lbl\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    batch_spec, batch_lbl = zip(*batch)\n",
        "\n",
        "    batch_spec_pad = pad_sequence(batch_spec, batch_first=True)\n",
        "    lengths_spec = [len(seq) for seq in batch_spec]\n",
        "\n",
        "\n",
        "    return batch_spec_pad, torch.tensor(lengths_spec), torch.stack(batch_lbl, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHqT3TtzKeXl"
      },
      "outputs": [],
      "source": [
        "class MSDatasetTest(torch.utils.data.Dataset):\n",
        "  def __init__(self, file, map=THREEMER_MAP):\n",
        "    with open(file, 'r') as f:\n",
        "      specs = f.read().strip().split('\\n\\n')\n",
        "      self.spectra = []\n",
        "      self.length = len(specs)\n",
        "\n",
        "      for spec in specs:\n",
        "        lines = spec.strip().split('\\n')\n",
        "        i = 1\n",
        "        while 'Num peaks: ' not in lines[i]:\n",
        "          i += 1\n",
        "        spec_len = int(lines[i].split('Num peaks: ')[1])\n",
        "        spectrum = np.zeros((spec_len, 2))\n",
        "        i += 1\n",
        "        for j in range(i, i + spec_len):\n",
        "          nums = lines[j].split('\\t')\n",
        "          spectrum[j-i,0] = float(nums[0])\n",
        "          spectrum[j-i,1] = float(nums[1])\n",
        "        self.spectra.append(spectrum)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "  def __getitem__(self, ind):\n",
        "    spec = torch.FloatTensor(self.spectra[ind])\n",
        "    return spec\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    batch_spec = batch\n",
        "\n",
        "    batch_spec_pad = pad_sequence(batch_spec, batch_first=True)\n",
        "    lengths_spec = [len(seq) for seq in batch_spec]\n",
        "\n",
        "\n",
        "    return batch_spec_pad, torch.tensor(lengths_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwVGAP4sybxd"
      },
      "outputs": [],
      "source": [
        "train_file = '/content/human_consensus_final_true_lib.msp'\n",
        "valid_file = '/content/mouse_consensus_final_true_lib.msp'\n",
        "\n",
        "# Feel free to add more items here\n",
        "config = {\n",
        "    \"lr\"         : 1e-3,\n",
        "    \"epochs\"     : 30,\n",
        "    \"batch_size\" : 128  # Increase if your device can handle it\n",
        "}\n",
        "\n",
        "dropout = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnutaIbEyfty",
        "outputId": "02936ec8-6692-4ca0-fa93-75f08f85b512"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGFtoXoPqUow",
        "outputId": "0a35b5f8-33f4-4c0e-c808-fbda5b0cb80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8000\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "abundance_train = np.zeros(8000)\n",
        "train_data = MSDataset(train_file, abundance_train)\n",
        "print(np.sum(abundance_train == np.zeros(8000)))\n",
        "print(np.average(abundance_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpcwXubOyhls",
        "outputId": "545c1291-ece3-4ca9-a2ae-5a3e5cc1781f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size:  128\n",
            "Train dataset samples = 340356, batches = 2660\n",
            "Val dataset samples = 149458, batches = 1168\n"
          ]
        }
      ],
      "source": [
        "# Create objects for the dataset class\n",
        "train_data = MSDataset(train_file)\n",
        "abundance_train = train_data.abundance\n",
        "val_data = MSDataset(valid_file)\n",
        "\n",
        "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data,\n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    collate_fn = train_data.collate_fn,\n",
        "    shuffle     = True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data,\n",
        "    num_workers = 2,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    collate_fn = val_data.collate_fn,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#     dataset     = test_data,\n",
        "#     num_workers = 2,\n",
        "#     batch_size  = config['batch_size'],\n",
        "#     pin_memory  = True,\n",
        "#     collate_fn = test_data.collate_fn,\n",
        "#     shuffle     = False\n",
        "# )\n",
        "\n",
        "print(\"Batch size: \", config['batch_size'])\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "# print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4ceJbinhfyQ",
        "outputId": "75a62355-4ae8-4f65-e843-7c0898ad5202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.072714028125\n"
          ]
        }
      ],
      "source": [
        "abundance_train = train_data.abundance\n",
        "print(np.average(1/abundance_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVj2QJrw_xrJ",
        "outputId": "925b65c5-15b0-4549-fffe-a2d7c791ad97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 4000, 1]) torch.Size([128]) torch.Size([128, 8000])\n"
          ]
        }
      ],
      "source": [
        "# sanity check\n",
        "for data in train_loader:\n",
        "    x, lx, y = data\n",
        "    print(x.shape, lx.shape, y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlF9f8MEzZxk"
      },
      "outputs": [],
      "source": [
        "# Utils for network\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "class PermuteBlock(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.transpose(1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyZzDpycM_v_"
      },
      "outputs": [],
      "source": [
        "class ResBlock(torch.nn.Module):\n",
        "    def __init__(self, in_chan, out_chan):\n",
        "        super().__init__()\n",
        "\n",
        "        stride = 1\n",
        "        self.convert = (in_chan != out_chan)\n",
        "        if self.convert:\n",
        "          stride = 2\n",
        "          self.increase = torch.nn.Conv1d(in_chan, out_chan, 1, stride = stride)\n",
        "\n",
        "        self.conv1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(in_chan, out_chan, 3, padding = 1, stride = stride),\n",
        "            torch.nn.Dropout(p=dropout, inplace=True),\n",
        "            torch.nn.BatchNorm1d(out_chan),\n",
        "            torch.nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.conv2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(out_chan, out_chan, 3, padding = 1),\n",
        "            # torch.nn.Dropout(p=dropout, inplace=True),\n",
        "            torch.nn.BatchNorm1d(out_chan)\n",
        "            )\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "      resid = x\n",
        "      if self.convert:\n",
        "        resid = self.increase.forward(x)\n",
        "      out = self.conv1.forward(x)\n",
        "      out = self.conv2.forward(out)\n",
        "      out += resid\n",
        "      return self.relu.forward(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g29enWtM_Fu"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, input_size, encoder_hidden_size, cnn_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=7, stride = 3, padding=7//2),\n",
        "            torch.nn.BatchNorm1d(64),\n",
        "            torch.nn.ReLU(),\n",
        "        )\n",
        "        self.pool = torch.nn.Sequential(torch.nn.MaxPool1d(kernel_size = 3, stride = 1))\n",
        "        self.backbone = torch.nn.Sequential(\n",
        "          ResBlock(64, 64),\n",
        "          ResBlock(64, 64),\n",
        "          # ResBlock(64, cnn_size)\n",
        "          ResBlock(64, 128),\n",
        "          ResBlock(128, 128),\n",
        "          ResBlock(128, 256),\n",
        "          # ResBlock(256, cnn_size)\n",
        "          ResBlock(256, 256),\n",
        "          ResBlock(256, 512),\n",
        "          ResBlock(512, cnn_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, x_lens):\n",
        "        x = x.transpose(1,2)\n",
        "        out = self.embedding(x)\n",
        "        out = self.pool(out)\n",
        "        out = self.backbone(out)\n",
        "        x = x.transpose(1,2)\n",
        "        out = torch.reshape(out, (out.shape[0], -1))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0y361HkzacJ"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, input_size, encoder_hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        cnn_size = encoder_hidden_size\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            PermuteBlock(), torch.nn.Conv1d(in_channels=input_size, out_channels=cnn_size//2, kernel_size=3, padding=1), PermuteBlock(),\n",
        "            torch.nn.ReLU(),\n",
        "            PermuteBlock(), torch.nn.Conv1d(in_channels=cnn_size//2, out_channels=cnn_size, kernel_size=3, padding=1), PermuteBlock(),\n",
        "            torch.nn.ReLU(),\n",
        "            # PermuteBlock(), torch.nn.Conv1d(in_channels=cnn_size//4, out_channels=cnn_size//2, kernel_size=3, padding=1), PermuteBlock(),\n",
        "            # torch.nn.ReLU(),\n",
        "            # PermuteBlock(), torch.nn.Conv1d(in_channels=cnn_size//2, out_channels=cnn_size, kernel_size=3, padding=1), PermuteBlock(),\n",
        "            # torch.nn.ReLU(),\n",
        "            # PermuteBlock(), torch.nn.Conv1d(in_channels=cnn_size//2, out_channels=cnn_size, kernel_size=5, padding=2), PermuteBlock()\n",
        "            # torch.nn.ReLU(),\n",
        "            # PermuteBlock(), torch.nn.AvgPool1d(kernel_size=3, padding = 1), PermuteBlock()\n",
        "            # PermuteBlock(), torch.nn.Conv1d(in_channels=cnn_size//2, out_channels=cnn_size, kernel_size=5, padding=2), PermuteBlock(),\n",
        "            # torch.nn.ReLU(),\n",
        "            # PermuteBlock(), torch.nn.MaxPool1d(kernel_size=5, padding = 2), PermuteBlock()\n",
        "        )\n",
        "        # self.rnn1 = torch.nn.RNN(input_size = cnn_size, num_layers=4, hidden_size = encoder_hidden_size//2, bidirectional=True, batch_first=True, dropout=0.3)\n",
        "        # self.rnn2 = torch.nn.RNN(input_size = encoder_hidden_size, hidden_size = encoder_hidden_size//2, bidirectional=True, batch_first=True)\n",
        "        self.rnn1 = torch.nn.LSTM(input_size = cnn_size, num_layers=4, hidden_size = encoder_hidden_size//2, bidirectional=True, batch_first=True, dropout=0.3)\n",
        "        self.rnn2 = torch.nn.LSTM(input_size = encoder_hidden_size, hidden_size = encoder_hidden_size//2, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x, x_lens):\n",
        "        x = self.embedding(x)\n",
        "        # TODO: Pack Padded Sequence\n",
        "        x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "        x_packed, _ = self.rnn1(x_packed)\n",
        "        _, out = self.rnn2(x_packed)\n",
        "        out, _ = out\n",
        "        out = torch.reshape(out, (out.shape[0]//2, out.shape[1], out.shape[2]*2))\n",
        "        out = torch.squeeze(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqx90RZV2p4m"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, output_size= 8000):\n",
        "        super().__init__()\n",
        "\n",
        "        factor = 84 # for 256\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.BatchNorm1d(embed_size*factor),\n",
        "            torch.nn.Linear(embed_size*factor, 1024),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p=0.3, inplace=True),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.Linear(1024, 2048),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(p=0.3, inplace=True),\n",
        "            torch.nn.BatchNorm1d(2048),\n",
        "            torch.nn.Linear(2048, output_size)\n",
        "        )\n",
        "\n",
        "        # self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, encoder_out):\n",
        "        out = self.mlp(encoder_out)\n",
        "        # out = self.softmax(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHM0ddGr6O8J"
      },
      "outputs": [],
      "source": [
        "class MSModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, cnn_size = 256, embed_size= 1024, output_size= 8000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder        = Encoder(input_size, embed_size, cnn_size)\n",
        "        self.decoder        = Decoder(embed_size, output_size)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, lengths_x):\n",
        "\n",
        "        encoder_out  = self.encoder(x, lengths_x)\n",
        "        decoder_out                 = self.decoder(encoder_out)\n",
        "\n",
        "        return decoder_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1us4Qlzy6eEZ"
      },
      "outputs": [],
      "source": [
        "model = MSModel(\n",
        "    input_size  = 1,\n",
        "    cnn_size = 256,\n",
        "    embed_size  = 256\n",
        ").to(device)\n",
        "\n",
        "# model = MSModel(\n",
        "#     input_size  = 2,\n",
        "#     embed_size  = 128\n",
        "# ).to(device)\n",
        "# print(model)\n",
        "# summary(model, x.to(device), lx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gw4iLABBZo_"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss(pos_weight = torch.tensor(abundance_train).to(device))\n",
        "\n",
        "optimizer =  torch.optim.Adam(model.parameters(), config['lr'], weight_decay=0.1)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 3, factor=0.7, threshold=0.1)\n",
        "\n",
        "# Mixed Precision, if you need it\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOAiejdKBgKF"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "    metric = MultilabelF1Score(num_labels=8000).to(device)\n",
        "    metric2 = MultilabelAccuracy(num_labels=8000).to(device)\n",
        "    metric3 = MultilabelSpecificity(num_labels=8000).to(device)\n",
        "\n",
        "    total_loss = 0\n",
        "    tf = 0\n",
        "    # tacc = 0\n",
        "    taccs = 0\n",
        "    prec = 0\n",
        "    rec = 0\n",
        "    spec = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, lx, y = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            h = model(x, lx)\n",
        "            loss = criterion(h, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        tf += metric(h, y).item()\n",
        "        taccs += metric2(h, y).item()\n",
        "        spec += metric3(h, y).item()\n",
        "        h = torch.sigmoid(h)\n",
        "        predictions = torch.round(h)\n",
        "\n",
        "        y = y.detach().cpu().numpy()\n",
        "        predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "        prec += precision_score(y, predictions, average='macro', zero_division=0)\n",
        "        rec += recall_score(y, predictions, average='macro', zero_division=0)\n",
        "        # tacc    += torch.sum(predictions == y).item()/(h.shape[0]*8000)\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            acc_s=\"{:.04f}%\".format(float(taccs*100 / (i + 1))),\n",
        "            f=\"{:.04f}%\".format(float(tf / (i + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # Another couple things you need for FP16.\n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        del x, y, lx, h, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    return total_loss / len(train_loader), tf / len(train_loader), taccs / len(train_loader), prec / len(train_loader), rec  / len(train_loader), spec  / len(train_loader)\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "    metric = MultilabelF1Score(num_labels=8000).to(device)\n",
        "    metric2 = MultilabelAccuracy(num_labels=8000).to(device)\n",
        "    metric3 = MultilabelSpecificity(num_labels=8000).to(device)\n",
        "\n",
        "    total_loss = 0\n",
        "    vf = 0\n",
        "    # vacc = 0\n",
        "    vaccs = 0\n",
        "    prec = 0\n",
        "    rec = 0\n",
        "    spec = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        x, lx, y = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            h = model(x, lx)\n",
        "            loss = criterion(h, y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        vf += metric(h, y).item()\n",
        "        vaccs += metric2(h, y).item()\n",
        "        spec += metric3(h, y).item()\n",
        "        h = torch.sigmoid(h)\n",
        "        predictions = torch.round(h)\n",
        "\n",
        "        y = y.detach().cpu().numpy()\n",
        "        predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "        prec += precision_score(y, predictions, average='macro', zero_division=0)\n",
        "        rec += recall_score(y, predictions, average='macro', zero_division=0)\n",
        "        # vf += metric(predictions, y).item()\n",
        "        # vacc    += torch.sum(predictions == y).item()/(h.shape[0]*8000)\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "                              acc=\"{:.04f}%\".format(float(vaccs*100 / (i + 1))),\n",
        "                              f=\"{:.04f}%\".format(float(vf / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "        del x, y, lx, h, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    total_loss = total_loss/len(val_loader)\n",
        "    vf /= len(val_loader)\n",
        "    vaccs /= len(val_loader)\n",
        "    prec /= len(val_loader)\n",
        "    rec /= len(val_loader)\n",
        "    spec /= len(val_loader)\n",
        "    return total_loss, vf, vaccs, prec, rec, spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6-HkUlQhm68"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'valid_f', optimizer= None, scheduler= None):\n",
        "\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    metric  = checkpoint[metric]\n",
        "\n",
        "    return [model, optimizer, scheduler, epoch, metric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgqiLdsahb2D"
      },
      "outputs": [],
      "source": [
        "best_model_path = '/content/drive/MyDrive/best_MS_RNN_model.pth'\n",
        "best_f = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "D84XYFiOgz_y",
        "outputId": "ba861259-85c7-4a51-cd66-03d9238940ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0017\tTrain Acc 0.7361\t Train Loss 1.3861\t Train Prec 0.0009\t Train Rec 0.0463\t Train Spec 0.7369\t Learning Rate 0.0010000\n",
            "\tVal F1 0.0014\tVal Acc 0.5905\t Val Loss 15.2030\t Val Prec 0.0007\t Val Rec 0.0412\t Val Spec 0.5907\n",
            "\n",
            "Epoch: 2/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0003\tTrain Acc 0.8707\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0149\t Train Spec 0.8721\t Learning Rate 0.0010000\n",
            "\tVal F1 0.0015\tVal Acc 0.5932\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0428\t Val Spec 0.5934\n",
            "\n",
            "Epoch: 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0003\tTrain Acc 0.8703\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0150\t Train Spec 0.8718\t Learning Rate 0.0010000\n",
            "\tVal F1 0.0015\tVal Acc 0.5896\t Val Loss 15.2031\t Val Prec 0.0008\t Val Rec 0.0437\t Val Spec 0.5897\n",
            "\n",
            "Epoch: 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0003\tTrain Acc 0.8702\t Train Loss 1.3837\t Train Prec 0.0001\t Train Rec 0.0151\t Train Spec 0.8716\t Learning Rate 0.0010000\n",
            "\tVal F1 0.0015\tVal Acc 0.5897\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0435\t Val Spec 0.5899\n",
            "\n",
            "Epoch: 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0003\tTrain Acc 0.8703\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0150\t Train Spec 0.8717\t Learning Rate 0.0010000\n",
            "\tVal F1 0.0014\tVal Acc 0.6045\t Val Loss 15.2030\t Val Prec 0.0007\t Val Rec 0.0404\t Val Spec 0.6047\n",
            "\n",
            "Epoch: 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0002\tTrain Acc 0.8949\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0104\t Train Spec 0.8964\t Learning Rate 0.0007000\n",
            "\tVal F1 0.0015\tVal Acc 0.5840\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0428\t Val Spec 0.5841\n",
            "\n",
            "Epoch: 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0002\tTrain Acc 0.8944\t Train Loss 1.3838\t Train Prec 0.0001\t Train Rec 0.0106\t Train Spec 0.8959\t Learning Rate 0.0007000\n",
            "\tVal F1 0.0015\tVal Acc 0.5774\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0432\t Val Spec 0.5775\n",
            "\n",
            "Epoch: 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0002\tTrain Acc 0.8940\t Train Loss 1.3837\t Train Prec 0.0001\t Train Rec 0.0106\t Train Spec 0.8956\t Learning Rate 0.0007000\n",
            "\tVal F1 0.0015\tVal Acc 0.5983\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0425\t Val Spec 0.5985\n",
            "\n",
            "Epoch: 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0002\tTrain Acc 0.8943\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0106\t Train Spec 0.8958\t Learning Rate 0.0007000\n",
            "\tVal F1 0.0015\tVal Acc 0.5786\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0440\t Val Spec 0.5787\n",
            "\n",
            "Epoch: 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val: 100%|██████████| 1168/1168 [09:34<00:00,  2.32it/s, acc=57.0347%, f=0.0015%, loss=15.2030]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9171\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0069\t Train Spec 0.9187\t Learning Rate 0.0004900\n",
            "\tVal F1 0.0015\tVal Acc 0.5703\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0431\t Val Spec 0.5705\n",
            "\n",
            "Epoch: 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9170\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0070\t Train Spec 0.9186\t Learning Rate 0.0004900\n",
            "\tVal F1 0.0016\tVal Acc 0.5649\t Val Loss 15.2027\t Val Prec 0.0008\t Val Rec 0.0447\t Val Spec 0.5650\n",
            "\n",
            "Epoch: 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9171\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0069\t Train Spec 0.9187\t Learning Rate 0.0004900\n",
            "\tVal F1 0.0015\tVal Acc 0.5750\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0442\t Val Spec 0.5751\n",
            "\n",
            "Epoch: 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9170\t Train Loss 1.3836\t Train Prec 0.0001\t Train Rec 0.0070\t Train Spec 0.9186\t Learning Rate 0.0004900\n",
            "\tVal F1 0.0015\tVal Acc 0.5766\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0431\t Val Spec 0.5767\n",
            "\n",
            "Epoch: 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9383\t Train Loss 1.3836\t Train Prec 0.0000\t Train Rec 0.0041\t Train Spec 0.9399\t Learning Rate 0.0003430\n",
            "\tVal F1 0.0015\tVal Acc 0.5841\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0418\t Val Spec 0.5842\n",
            "\n",
            "Epoch: 15/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9380\t Train Loss 1.3837\t Train Prec 0.0000\t Train Rec 0.0042\t Train Spec 0.9396\t Learning Rate 0.0003430\n",
            "\tVal F1 0.0015\tVal Acc 0.5695\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0427\t Val Spec 0.5696\n",
            "\n",
            "Epoch: 16/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9382\t Train Loss 1.3837\t Train Prec 0.0000\t Train Rec 0.0041\t Train Spec 0.9398\t Learning Rate 0.0003430\n",
            "\tVal F1 0.0015\tVal Acc 0.5590\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0435\t Val Spec 0.5591\n",
            "\n",
            "Epoch: 17/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0001\tTrain Acc 0.9381\t Train Loss 1.3837\t Train Prec 0.0000\t Train Rec 0.0042\t Train Spec 0.9398\t Learning Rate 0.0003430\n",
            "\tVal F1 0.0016\tVal Acc 0.5557\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0450\t Val Spec 0.5557\n",
            "\n",
            "Epoch: 18/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9558\t Train Loss 1.3837\t Train Prec 0.0000\t Train Rec 0.0023\t Train Spec 0.9575\t Learning Rate 0.0002401\n",
            "\tVal F1 0.0016\tVal Acc 0.5558\t Val Loss 15.2029\t Val Prec 0.0008\t Val Rec 0.0449\t Val Spec 0.5559\n",
            "\n",
            "Epoch: 19/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9563\t Train Loss 1.3836\t Train Prec 0.0000\t Train Rec 0.0022\t Train Spec 0.9580\t Learning Rate 0.0002401\n",
            "\tVal F1 0.0015\tVal Acc 0.5636\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0437\t Val Spec 0.5637\n",
            "\n",
            "Epoch: 20/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9556\t Train Loss 1.3838\t Train Prec 0.0000\t Train Rec 0.0023\t Train Spec 0.9573\t Learning Rate 0.0002401\n",
            "\tVal F1 0.0016\tVal Acc 0.5569\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0455\t Val Spec 0.5570\n",
            "\n",
            "Epoch: 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9562\t Train Loss 1.3840\t Train Prec 0.0000\t Train Rec 0.0022\t Train Spec 0.9578\t Learning Rate 0.0002401\n",
            "\tVal F1 0.0016\tVal Acc 0.5357\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0458\t Val Spec 0.5357\n",
            "\n",
            "Epoch: 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9706\t Train Loss 1.3837\t Train Prec 0.0000\t Train Rec 0.0011\t Train Spec 0.9723\t Learning Rate 0.0001681\n",
            "\tVal F1 0.0016\tVal Acc 0.5540\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0445\t Val Spec 0.5541\n",
            "\n",
            "Epoch: 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9710\t Train Loss 1.3842\t Train Prec 0.0000\t Train Rec 0.0010\t Train Spec 0.9727\t Learning Rate 0.0001681\n",
            "\tVal F1 0.0016\tVal Acc 0.5384\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0448\t Val Spec 0.5385\n",
            "\n",
            "Epoch: 24/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9709\t Train Loss 1.3837\t Train Prec 0.0000\t Train Rec 0.0011\t Train Spec 0.9726\t Learning Rate 0.0001681\n",
            "\tVal F1 0.0015\tVal Acc 0.5474\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0435\t Val Spec 0.5475\n",
            "\n",
            "Epoch: 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Val:   0%|          | 0/1168 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain F1 0.0000\tTrain Acc 0.9709\t Train Loss 1.3837\t Train Prec 0.0000\t Train Rec 0.0010\t Train Spec 0.9725\t Learning Rate 0.0001681\n",
            "\tVal F1 0.0016\tVal Acc 0.5505\t Val Loss 15.2030\t Val Prec 0.0008\t Val Rec 0.0446\t Val Spec 0.5506\n",
            "\n",
            "Epoch: 26/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/2660 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Train:  44%|████▍     | 1174/2660 [10:58<13:46,  1.80it/s, acc_s=98.1340%, f=0.0000%, loss=1.3833, lr=0.000118]"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "for epoch in range(0, config['epochs']):\n",
        "\n",
        "    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    train_loss, train_f, train_acc, precision_t, recall_t, spec_t   = train_model(model, train_loader, criterion, optimizer)\n",
        "    valid_loss, valid_f, valid_acc, precision_v, recall_v, spec_v  = validate_model(model, val_loader)\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    print(\"\\tTrain F1 {:.04f}\\tTrain Acc {:.04f}\\t Train Loss {:.04f}\\t Train Prec {:.04f}\\t Train Rec {:.04f}\\t Train Spec {:.04f}\\t Learning Rate {:.07f}\".format(train_f, train_acc, train_loss, precision_t, recall_t, spec_t, curr_lr))\n",
        "    print(\"\\tVal F1 {:.04f}\\tVal Acc {:.04f}\\t Val Loss {:.04f}\\t Val Prec {:.04f}\\t Val Rec {:.04f}\\t Val Spec {:.04f}\".format(valid_f, valid_acc, valid_loss, precision_v, recall_v, spec_v))\n",
        "\n",
        "\n",
        "\n",
        "    # if valid_f >= best_f:\n",
        "    #     best_f = valid_f\n",
        "    #     save_model(model, optimizer, scheduler, ['valid_f', valid_f], epoch, best_model_path)\n",
        "    #     print(\"Saved best model\")\n",
        "      # You may find it interesting to exlplore Wandb Artifcats to version your models"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}